2015-05-02 17:10:25,138 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = hwb-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.7.0_79
************************************************************/
2015-05-02 17:10:25,836 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-05-02 17:10:25,865 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2015-05-02 17:10:25,865 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-05-02 17:10:25,866 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-05-02 17:10:26,570 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2015-05-02 17:10:26,573 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2015-05-02 17:10:26,621 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2015-05-02 17:10:26,622 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2015-05-02 17:10:26,710 INFO org.apache.hadoop.hdfs.util.GSet: Computing capacity for map BlocksMap
2015-05-02 17:10:26,710 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-05-02 17:10:26,710 INFO org.apache.hadoop.hdfs.util.GSet: 2.0% max memory = 1013645312
2015-05-02 17:10:26,710 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-05-02 17:10:26,711 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-05-02 17:10:26,764 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hwb
2015-05-02 17:10:26,764 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-05-02 17:10:26,764 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2015-05-02 17:10:26,776 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-05-02 17:10:26,776 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-05-02 17:10:26,883 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2015-05-02 17:10:26,967 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: dfs.namenode.edits.toleration.length = 0
2015-05-02 17:10:26,967 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-05-02 17:10:26,982 INFO org.apache.hadoop.hdfs.server.common.Storage: Start loading image file /tmp/hadoop-hwb/dfs/name/current/fsimage
2015-05-02 17:10:26,982 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-05-02 17:10:26,984 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-05-02 17:10:26,985 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /tmp/hadoop-hwb/dfs/name/current/fsimage of size 109 bytes loaded in 0 seconds.
2015-05-02 17:10:26,985 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start loading edits file /tmp/hadoop-hwb/dfs/name/current/edits
2015-05-02 17:10:26,985 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: EOF of /tmp/hadoop-hwb/dfs/name/current/edits, reached end of edit log Number of transactions found: 0.  Bytes read: 4
2015-05-02 17:10:26,985 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start checking end of edit log (/tmp/hadoop-hwb/dfs/name/current/edits) ...
2015-05-02 17:10:26,985 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Checked the bytes after the end of edit log (/tmp/hadoop-hwb/dfs/name/current/edits):
2015-05-02 17:10:26,985 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Padding position  = -1 (-1 means padding not found)
2015-05-02 17:10:26,985 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Edit log length   = 4
2015-05-02 17:10:26,985 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Read length       = 4
2015-05-02 17:10:26,985 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Corruption length = 0
2015-05-02 17:10:26,985 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Toleration length = 0 (= dfs.namenode.edits.toleration.length)
2015-05-02 17:10:26,999 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Summary: |---------- Read=4 ----------|-- Corrupt=0 --|-- Pad=0 --|
2015-05-02 17:10:26,999 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edits file /tmp/hadoop-hwb/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-05-02 17:10:27,000 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /tmp/hadoop-hwb/dfs/name/current/fsimage of size 109 bytes saved in 0 seconds.
2015-05-02 17:10:27,070 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: closing edit log: position=4, editlog=/tmp/hadoop-hwb/dfs/name/current/edits
2015-05-02 17:10:27,071 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: close success: truncate to 4, editlog=/tmp/hadoop-hwb/dfs/name/current/edits
2015-05-02 17:10:27,145 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-05-02 17:10:27,145 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 387 msecs
2015-05-02 17:10:27,154 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.safemode.threshold.pct          = 0.9990000128746033
2015-05-02 17:10:27,154 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-05-02 17:10:27,154 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.safemode.extension              = 30000
2015-05-02 17:10:27,154 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks excluded by safe block count: 0 total blocks: 0 and thus the safe blocks: 0
2015-05-02 17:10:27,177 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2015-05-02 17:10:27,177 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2015-05-02 17:10:27,177 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2015-05-02 17:10:27,177 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2015-05-02 17:10:27,177 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 23 msec
2015-05-02 17:10:27,177 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2015-05-02 17:10:27,177 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2015-05-02 17:10:27,177 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2015-05-02 17:10:27,209 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2015-05-02 17:10:27,210 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2015-05-02 17:10:27,210 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2015-05-02 17:10:27,210 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2015-05-02 17:10:27,210 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2015-05-02 17:10:27,218 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2015-05-02 17:10:27,276 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort9000 registered.
2015-05-02 17:10:27,276 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort9000 registered.
2015-05-02 17:10:27,277 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:9000
2015-05-02 17:10:27,278 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2015-05-02 17:10:27,507 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-05-02 17:10:27,605 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-05-02 17:10:27,616 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2015-05-02 17:10:27,624 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2015-05-02 17:10:27,625 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2015-05-02 17:10:27,625 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2015-05-02 17:10:27,625 INFO org.mortbay.log: jetty-6.1.26
2015-05-02 17:10:28,207 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2015-05-02 17:10:28,207 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2015-05-02 17:10:28,216 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-05-02 17:10:28,217 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2015-05-02 17:10:28,226 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000: starting
2015-05-02 17:10:28,226 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000: starting
2015-05-02 17:10:28,227 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000: starting
2015-05-02 17:10:28,227 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000: starting
2015-05-02 17:10:28,237 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000: starting
2015-05-02 17:10:28,237 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000: starting
2015-05-02 17:10:28,238 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000: starting
2015-05-02 17:10:28,238 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000: starting
2015-05-02 17:10:28,238 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000: starting
2015-05-02 17:10:28,239 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000: starting
2015-05-02 17:10:41,318 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: node registration from 127.0.0.1:50010 storage DS-968557232-127.0.1.1-50010-1430579441315
2015-05-02 17:10:41,320 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2015-05-02 17:10:41,335 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.blocksBeingWrittenReport: from 127.0.0.1:50010 0 blocks
2015-05-02 17:10:41,342 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* processReport: from 127.0.0.1:50010, blocks: 0, processing time: 1 msecs
2015-05-02 17:10:50,355 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-hwb/mapred/system/jobtracker.info. blk_2146115774273189261_1001
2015-05-02 17:10:50,685 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_2146115774273189261_1001 size 4
2015-05-02 17:10:50,702 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  /tmp/hadoop-hwb/mapred/system/jobtracker.info from client DFSClient_NONMAPREDUCE_1235377181_1
2015-05-02 17:10:50,703 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-hwb/mapred/system/jobtracker.info is closed by DFSClient_NONMAPREDUCE_1235377181_1
2015-05-02 17:12:17,733 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2455)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2015-05-02 17:12:17,740 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2015-05-02 17:12:17,754 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2455)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2015-05-02 17:12:17,755 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2015-05-02 17:12:17,763 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:2784)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getListing(NameNode.java:925)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2015-05-02 17:12:17,764 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2015-05-02 17:12:44,249 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at hwb-VirtualBox/127.0.1.1
************************************************************/
2015-05-02 17:13:20,173 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = hwb-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.7.0_79
************************************************************/
2015-05-02 17:13:20,813 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-05-02 17:13:20,843 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2015-05-02 17:13:20,844 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-05-02 17:13:20,844 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-05-02 17:13:21,765 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2015-05-02 17:13:21,769 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2015-05-02 17:13:21,772 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2015-05-02 17:13:21,772 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2015-05-02 17:13:21,916 INFO org.apache.hadoop.hdfs.util.GSet: Computing capacity for map BlocksMap
2015-05-02 17:13:21,916 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-05-02 17:13:21,916 INFO org.apache.hadoop.hdfs.util.GSet: 2.0% max memory = 1013645312
2015-05-02 17:13:21,916 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-05-02 17:13:21,916 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-05-02 17:13:21,986 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hwb
2015-05-02 17:13:21,986 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-05-02 17:13:21,986 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2015-05-02 17:13:21,992 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-05-02 17:13:21,992 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-05-02 17:13:22,218 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2015-05-02 17:13:22,373 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: dfs.namenode.edits.toleration.length = 0
2015-05-02 17:13:22,373 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-05-02 17:13:22,400 INFO org.apache.hadoop.hdfs.server.common.Storage: Start loading image file /tmp/hadoop-hwb/dfs/name/current/fsimage
2015-05-02 17:13:22,402 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-05-02 17:13:22,410 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-05-02 17:13:22,410 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /tmp/hadoop-hwb/dfs/name/current/fsimage of size 109 bytes loaded in 0 seconds.
2015-05-02 17:13:22,410 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start loading edits file /tmp/hadoop-hwb/dfs/name/current/edits
2015-05-02 17:13:22,487 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Invalid opcode, reached end of edit log Number of transactions found: 10.  Bytes read: 828
2015-05-02 17:13:22,487 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start checking end of edit log (/tmp/hadoop-hwb/dfs/name/current/edits) ...
2015-05-02 17:13:22,690 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Checked the bytes after the end of edit log (/tmp/hadoop-hwb/dfs/name/current/edits):
2015-05-02 17:13:22,690 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Padding position  = 828 (-1 means padding not found)
2015-05-02 17:13:22,690 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Edit log length   = 1048580
2015-05-02 17:13:22,690 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Read length       = 828
2015-05-02 17:13:22,691 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Corruption length = 0
2015-05-02 17:13:22,691 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Toleration length = 0 (= dfs.namenode.edits.toleration.length)
2015-05-02 17:13:22,694 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Summary: |---------- Read=828 ----------|-- Corrupt=0 --|-- Pad=1047752 --|
2015-05-02 17:13:22,694 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edits file /tmp/hadoop-hwb/dfs/name/current/edits of size 1048580 edits # 10 loaded in 0 seconds.
2015-05-02 17:13:22,697 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /tmp/hadoop-hwb/dfs/name/current/fsimage of size 557 bytes saved in 0 seconds.
2015-05-02 17:13:22,805 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: closing edit log: position=4, editlog=/tmp/hadoop-hwb/dfs/name/current/edits
2015-05-02 17:13:22,806 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: close success: truncate to 4, editlog=/tmp/hadoop-hwb/dfs/name/current/edits
2015-05-02 17:13:22,909 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-05-02 17:13:22,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 954 msecs
2015-05-02 17:13:22,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.safemode.threshold.pct          = 0.9990000128746033
2015-05-02 17:13:22,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-05-02 17:13:22,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.safemode.extension              = 30000
2015-05-02 17:13:22,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks excluded by safe block count: 0 total blocks: 1 and thus the safe blocks: 1
2015-05-02 17:13:22,911 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON 
The reported blocks is only 0 but the threshold is 0.9990 and the total blocks 1. Safe mode will be turned off automatically.
2015-05-02 17:13:22,922 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2015-05-02 17:13:22,941 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2015-05-02 17:13:23,004 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort9000 registered.
2015-05-02 17:13:23,004 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort9000 registered.
2015-05-02 17:13:23,006 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2015-05-02 17:13:23,007 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:9000
2015-05-02 17:13:23,342 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-05-02 17:13:23,668 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-05-02 17:13:23,691 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2015-05-02 17:13:23,744 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2015-05-02 17:13:23,759 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2015-05-02 17:13:23,759 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2015-05-02 17:13:23,759 INFO org.mortbay.log: jetty-6.1.26
2015-05-02 17:13:26,279 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2015-05-02 17:13:26,279 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2015-05-02 17:13:26,288 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-05-02 17:13:26,291 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2015-05-02 17:13:26,301 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000: starting
2015-05-02 17:13:26,301 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000: starting
2015-05-02 17:13:26,305 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000: starting
2015-05-02 17:13:26,308 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000: starting
2015-05-02 17:13:26,315 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000: starting
2015-05-02 17:13:26,320 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000: starting
2015-05-02 17:13:26,321 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000: starting
2015-05-02 17:13:26,321 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000: starting
2015-05-02 17:13:26,321 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000: starting
2015-05-02 17:13:26,345 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000: starting
2015-05-02 17:13:30,574 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: node registration from 127.0.0.1:50010 storage DS-968557232-127.0.1.1-50010-1430579441315
2015-05-02 17:13:30,592 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2015-05-02 17:13:30,621 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.blocksBeingWrittenReport: from 127.0.0.1:50010 0 blocks
2015-05-02 17:13:30,808 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered 
The reported blocks 1 has reached the threshold 0.9990 of total blocks 1. Safe mode will be turned off automatically in 29 seconds.
2015-05-02 17:13:30,808 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* processReport: from 127.0.0.1:50010, blocks: 1, processing time: 55 msecs
2015-05-02 17:13:32,737 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2455)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2015-05-02 17:13:32,738 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2015-05-02 17:13:32,870 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2455)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2015-05-02 17:13:32,871 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2015-05-02 17:13:32,949 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:2784)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getListing(NameNode.java:925)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2015-05-02 17:13:32,949 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2015-05-02 17:13:38,202 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2455)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2015-05-02 17:13:38,203 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2015-05-02 17:13:38,217 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2455)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2015-05-02 17:13:38,218 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2015-05-02 17:13:38,257 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:2784)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getListing(NameNode.java:925)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2015-05-02 17:13:38,258 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2015-05-02 17:13:50,888 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON 
The reported blocks 1 has reached the threshold 0.9990 of total blocks 1. Safe mode will be turned off automatically in 9 seconds.
2015-05-02 17:14:00,903 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 1
2015-05-02 17:14:00,904 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2015-05-02 17:14:00,904 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2015-05-02 17:14:00,904 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2015-05-02 17:14:00,904 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 14 msec
2015-05-02 17:14:00,904 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 38 secs
2015-05-02 17:14:00,904 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2015-05-02 17:14:00,904 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2015-05-02 17:14:00,904 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2015-05-02 17:14:01,727 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addToInvalidates: blk_2146115774273189261 to 127.0.0.1:50010 
2015-05-02 17:14:01,783 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-hwb/mapred/system/jobtracker.info. blk_9071054462373776309_1002
2015-05-02 17:14:01,833 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_9071054462373776309_1002 size 4
2015-05-02 17:14:01,835 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  /tmp/hadoop-hwb/mapred/system/jobtracker.info from client DFSClient_NONMAPREDUCE_-558070041_1
2015-05-02 17:14:01,836 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-hwb/mapred/system/jobtracker.info is closed by DFSClient_NONMAPREDUCE_-558070041_1
2015-05-02 17:14:01,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2015-05-02 17:14:01,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2015-05-02 17:14:01,977 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 127.0.0.1:50010 to delete  blk_2146115774273189261_1001
2015-05-02 17:14:01,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 1 blocks in 0 msec
2015-05-02 17:14:01,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 1 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2015-05-02 17:14:20,469 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at hwb-VirtualBox/127.0.1.1
************************************************************/
2015-05-02 17:37:50,536 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = hwb-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.7.0_79
************************************************************/
2015-05-02 17:37:50,787 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-05-02 17:37:50,804 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2015-05-02 17:37:50,804 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-05-02 17:37:50,804 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-05-02 17:37:51,249 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2015-05-02 17:37:51,268 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2015-05-02 17:37:51,302 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2015-05-02 17:37:51,311 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2015-05-02 17:37:51,345 INFO org.apache.hadoop.hdfs.util.GSet: Computing capacity for map BlocksMap
2015-05-02 17:37:51,345 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-05-02 17:37:51,345 INFO org.apache.hadoop.hdfs.util.GSet: 2.0% max memory = 1013645312
2015-05-02 17:37:51,345 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-05-02 17:37:51,345 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-05-02 17:37:51,377 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hwb
2015-05-02 17:37:51,377 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-05-02 17:37:51,377 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2015-05-02 17:37:51,384 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-05-02 17:37:51,384 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-05-02 17:37:51,457 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2015-05-02 17:37:51,572 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: dfs.namenode.edits.toleration.length = 0
2015-05-02 17:37:51,572 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-05-02 17:37:51,580 INFO org.apache.hadoop.hdfs.server.common.Storage: Start loading image file /tmp/hadoop-hwb/dfs/name/current/fsimage
2015-05-02 17:37:51,580 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-05-02 17:37:51,583 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-05-02 17:37:51,583 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /tmp/hadoop-hwb/dfs/name/current/fsimage of size 109 bytes loaded in 0 seconds.
2015-05-02 17:37:51,584 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start loading edits file /tmp/hadoop-hwb/dfs/name/current/edits
2015-05-02 17:37:51,584 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: EOF of /tmp/hadoop-hwb/dfs/name/current/edits, reached end of edit log Number of transactions found: 0.  Bytes read: 4
2015-05-02 17:37:51,584 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start checking end of edit log (/tmp/hadoop-hwb/dfs/name/current/edits) ...
2015-05-02 17:37:51,584 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Checked the bytes after the end of edit log (/tmp/hadoop-hwb/dfs/name/current/edits):
2015-05-02 17:37:51,584 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Padding position  = -1 (-1 means padding not found)
2015-05-02 17:37:51,584 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Edit log length   = 4
2015-05-02 17:37:51,584 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Read length       = 4
2015-05-02 17:37:51,584 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Corruption length = 0
2015-05-02 17:37:51,584 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Toleration length = 0 (= dfs.namenode.edits.toleration.length)
2015-05-02 17:37:51,591 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Summary: |---------- Read=4 ----------|-- Corrupt=0 --|-- Pad=0 --|
2015-05-02 17:37:51,591 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edits file /tmp/hadoop-hwb/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-05-02 17:37:51,592 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /tmp/hadoop-hwb/dfs/name/current/fsimage of size 109 bytes saved in 0 seconds.
2015-05-02 17:37:51,706 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: closing edit log: position=4, editlog=/tmp/hadoop-hwb/dfs/name/current/edits
2015-05-02 17:37:51,706 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: close success: truncate to 4, editlog=/tmp/hadoop-hwb/dfs/name/current/edits
2015-05-02 17:37:51,739 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-05-02 17:37:51,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 373 msecs
2015-05-02 17:37:51,746 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.safemode.threshold.pct          = 0.9990000128746033
2015-05-02 17:37:51,746 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-05-02 17:37:51,746 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.safemode.extension              = 30000
2015-05-02 17:37:51,746 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks excluded by safe block count: 0 total blocks: 0 and thus the safe blocks: 0
2015-05-02 17:37:51,786 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2015-05-02 17:37:51,786 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2015-05-02 17:37:51,786 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2015-05-02 17:37:51,786 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2015-05-02 17:37:51,786 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 39 msec
2015-05-02 17:37:51,786 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2015-05-02 17:37:51,787 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2015-05-02 17:37:51,787 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2015-05-02 17:37:51,828 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2015-05-02 17:37:51,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 1 msec
2015-05-02 17:37:51,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 1 msec processing time, 1 msec clock time, 1 cycles
2015-05-02 17:37:51,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2015-05-02 17:37:51,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2015-05-02 17:37:51,836 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2015-05-02 17:37:51,911 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2015-05-02 17:37:51,912 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort9000 registered.
2015-05-02 17:37:51,913 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort9000 registered.
2015-05-02 17:37:51,919 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:9000
2015-05-02 17:37:52,171 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-05-02 17:37:52,319 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-05-02 17:37:52,348 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2015-05-02 17:37:52,358 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2015-05-02 17:37:52,359 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2015-05-02 17:37:52,359 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2015-05-02 17:37:52,359 INFO org.mortbay.log: jetty-6.1.26
2015-05-02 17:37:54,025 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2015-05-02 17:37:54,025 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2015-05-02 17:37:54,025 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-05-02 17:37:54,026 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2015-05-02 17:37:54,045 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000: starting
2015-05-02 17:37:54,046 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000: starting
2015-05-02 17:37:54,046 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000: starting
2015-05-02 17:37:54,061 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000: starting
2015-05-02 17:37:54,061 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000: starting
2015-05-02 17:37:54,061 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000: starting
2015-05-02 17:37:54,062 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000: starting
2015-05-02 17:37:54,062 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000: starting
2015-05-02 17:37:54,062 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000: starting
2015-05-02 17:37:54,062 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000: starting
2015-05-02 17:37:59,476 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: node registration from 127.0.0.1:50010 storage DS-534192095-127.0.1.1-50010-1430581079416
2015-05-02 17:37:59,478 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2015-05-02 17:37:59,538 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.blocksBeingWrittenReport: from 127.0.0.1:50010 0 blocks
2015-05-02 17:37:59,618 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* processReport: from 127.0.0.1:50010, blocks: 0, processing time: 1 msecs
2015-05-02 17:38:03,327 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-hwb/mapred/system/jobtracker.info. blk_-8634866625776651293_1001
2015-05-02 17:38:03,695 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_-8634866625776651293_1001 size 4
2015-05-02 17:38:03,699 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  /tmp/hadoop-hwb/mapred/system/jobtracker.info from client DFSClient_NONMAPREDUCE_-906057327_1
2015-05-02 17:38:03,699 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-hwb/mapred/system/jobtracker.info is closed by DFSClient_NONMAPREDUCE_-906057327_1
2015-05-02 17:38:20,462 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2455)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2015-05-02 17:38:20,464 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2015-05-02 17:38:20,488 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2455)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2015-05-02 17:38:20,488 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2015-05-02 17:38:20,517 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:2784)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getListing(NameNode.java:925)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2015-05-02 17:38:20,525 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2015-05-02 17:38:38,284 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at hwb-VirtualBox/127.0.1.1
************************************************************/
2015-05-02 18:59:54,085 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = hwb-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.7.0_79
************************************************************/
2015-05-02 18:59:54,844 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-05-02 18:59:54,872 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2015-05-02 18:59:54,873 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-05-02 18:59:54,873 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-05-02 18:59:55,789 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2015-05-02 18:59:55,814 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2015-05-02 18:59:55,868 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2015-05-02 18:59:55,869 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2015-05-02 18:59:56,045 INFO org.apache.hadoop.hdfs.util.GSet: Computing capacity for map BlocksMap
2015-05-02 18:59:56,045 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-05-02 18:59:56,045 INFO org.apache.hadoop.hdfs.util.GSet: 2.0% max memory = 1013645312
2015-05-02 18:59:56,045 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-05-02 18:59:56,045 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-05-02 18:59:56,198 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hwb
2015-05-02 18:59:56,198 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-05-02 18:59:56,198 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2015-05-02 18:59:56,215 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-05-02 18:59:56,215 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-05-02 18:59:56,340 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2015-05-02 18:59:56,560 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: dfs.namenode.edits.toleration.length = 0
2015-05-02 18:59:56,560 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-05-02 18:59:56,577 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-hwb/dfs/name does not exist
2015-05-02 18:59:56,583 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /tmp/hadoop-hwb/dfs/name is in an inconsistent state: storage directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:304)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:104)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:427)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:395)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:299)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:569)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1479)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1488)
2015-05-02 18:59:56,617 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /tmp/hadoop-hwb/dfs/name is in an inconsistent state: storage directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:304)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:104)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:427)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:395)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:299)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:569)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1479)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1488)

2015-05-02 18:59:56,618 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at hwb-VirtualBox/127.0.1.1
************************************************************/
2015-05-02 19:00:57,739 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = hwb-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.7.0_79
************************************************************/
2015-05-02 19:00:57,950 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-05-02 19:00:57,965 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2015-05-02 19:00:57,966 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-05-02 19:00:57,966 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-05-02 19:00:58,415 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2015-05-02 19:00:58,418 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2015-05-02 19:00:58,429 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2015-05-02 19:00:58,430 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2015-05-02 19:00:58,558 INFO org.apache.hadoop.hdfs.util.GSet: Computing capacity for map BlocksMap
2015-05-02 19:00:58,558 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-05-02 19:00:58,558 INFO org.apache.hadoop.hdfs.util.GSet: 2.0% max memory = 1013645312
2015-05-02 19:00:58,558 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-05-02 19:00:58,558 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-05-02 19:00:58,620 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hwb
2015-05-02 19:00:58,620 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-05-02 19:00:58,620 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2015-05-02 19:00:58,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-05-02 19:00:58,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-05-02 19:00:58,804 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2015-05-02 19:00:58,961 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: dfs.namenode.edits.toleration.length = 0
2015-05-02 19:00:58,961 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-05-02 19:00:58,964 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-hwb/dfs/name does not exist
2015-05-02 19:00:58,965 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /tmp/hadoop-hwb/dfs/name is in an inconsistent state: storage directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:304)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:104)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:427)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:395)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:299)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:569)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1479)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1488)
2015-05-02 19:00:58,980 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /tmp/hadoop-hwb/dfs/name is in an inconsistent state: storage directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:304)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:104)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:427)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:395)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:299)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:569)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1479)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1488)

2015-05-02 19:00:58,981 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at hwb-VirtualBox/127.0.1.1
************************************************************/
2015-05-02 19:01:47,095 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = hwb-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.7.0_79
************************************************************/
2015-05-02 19:01:47,307 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-05-02 19:01:47,322 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2015-05-02 19:01:47,323 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-05-02 19:01:47,323 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-05-02 19:01:47,723 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2015-05-02 19:01:47,726 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2015-05-02 19:01:47,771 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2015-05-02 19:01:47,772 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2015-05-02 19:01:47,826 INFO org.apache.hadoop.hdfs.util.GSet: Computing capacity for map BlocksMap
2015-05-02 19:01:47,826 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-05-02 19:01:47,826 INFO org.apache.hadoop.hdfs.util.GSet: 2.0% max memory = 1013645312
2015-05-02 19:01:47,826 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-05-02 19:01:47,826 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-05-02 19:01:47,941 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hwb
2015-05-02 19:01:47,942 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-05-02 19:01:47,942 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2015-05-02 19:01:47,961 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-05-02 19:01:47,961 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-05-02 19:01:48,026 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2015-05-02 19:01:48,191 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: dfs.namenode.edits.toleration.length = 0
2015-05-02 19:01:48,191 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-05-02 19:01:48,215 INFO org.apache.hadoop.hdfs.server.common.Storage: Start loading image file /tmp/hadoop-hwb/dfs/name/current/fsimage
2015-05-02 19:01:48,215 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-05-02 19:01:48,234 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-05-02 19:01:48,234 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /tmp/hadoop-hwb/dfs/name/current/fsimage of size 109 bytes loaded in 0 seconds.
2015-05-02 19:01:48,234 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start loading edits file /tmp/hadoop-hwb/dfs/name/current/edits
2015-05-02 19:01:48,234 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: EOF of /tmp/hadoop-hwb/dfs/name/current/edits, reached end of edit log Number of transactions found: 0.  Bytes read: 4
2015-05-02 19:01:48,234 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start checking end of edit log (/tmp/hadoop-hwb/dfs/name/current/edits) ...
2015-05-02 19:01:48,235 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Checked the bytes after the end of edit log (/tmp/hadoop-hwb/dfs/name/current/edits):
2015-05-02 19:01:48,235 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Padding position  = -1 (-1 means padding not found)
2015-05-02 19:01:48,235 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Edit log length   = 4
2015-05-02 19:01:48,235 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Read length       = 4
2015-05-02 19:01:48,235 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Corruption length = 0
2015-05-02 19:01:48,235 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Toleration length = 0 (= dfs.namenode.edits.toleration.length)
2015-05-02 19:01:48,239 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Summary: |---------- Read=4 ----------|-- Corrupt=0 --|-- Pad=0 --|
2015-05-02 19:01:48,244 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edits file /tmp/hadoop-hwb/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-05-02 19:01:48,247 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /tmp/hadoop-hwb/dfs/name/current/fsimage of size 109 bytes saved in 0 seconds.
2015-05-02 19:01:48,383 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: closing edit log: position=4, editlog=/tmp/hadoop-hwb/dfs/name/current/edits
2015-05-02 19:01:48,384 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: close success: truncate to 4, editlog=/tmp/hadoop-hwb/dfs/name/current/edits
2015-05-02 19:01:48,468 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-05-02 19:01:48,469 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 568 msecs
2015-05-02 19:01:48,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.safemode.threshold.pct          = 0.9990000128746033
2015-05-02 19:01:48,480 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-05-02 19:01:48,480 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.safemode.extension              = 30000
2015-05-02 19:01:48,480 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks excluded by safe block count: 0 total blocks: 0 and thus the safe blocks: 0
2015-05-02 19:01:48,495 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2015-05-02 19:01:48,495 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2015-05-02 19:01:48,496 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2015-05-02 19:01:48,496 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2015-05-02 19:01:48,496 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 16 msec
2015-05-02 19:01:48,496 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2015-05-02 19:01:48,496 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2015-05-02 19:01:48,496 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2015-05-02 19:01:48,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 1 msec
2015-05-02 19:01:48,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 1 msec processing time, 1 msec clock time, 1 cycles
2015-05-02 19:01:48,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2015-05-02 19:01:48,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2015-05-02 19:01:48,532 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2015-05-02 19:01:48,552 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2015-05-02 19:01:48,591 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2015-05-02 19:01:48,593 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort54310 registered.
2015-05-02 19:01:48,594 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort54310 registered.
2015-05-02 19:01:48,595 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: master/10.0.2.9:54310
2015-05-02 19:01:48,828 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-05-02 19:01:48,975 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-05-02 19:01:49,000 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2015-05-02 19:01:49,019 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2015-05-02 19:01:49,020 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2015-05-02 19:01:49,020 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2015-05-02 19:01:49,020 INFO org.mortbay.log: jetty-6.1.26
2015-05-02 19:01:51,136 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2015-05-02 19:01:51,136 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2015-05-02 19:01:51,139 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-05-02 19:01:51,142 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2015-05-02 19:01:51,155 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 54310: starting
2015-05-02 19:01:51,169 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 54310: starting
2015-05-02 19:01:51,179 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 54310: starting
2015-05-02 19:01:51,180 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 54310: starting
2015-05-02 19:01:51,180 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 54310: starting
2015-05-02 19:01:51,180 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 54310: starting
2015-05-02 19:01:51,180 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 54310: starting
2015-05-02 19:01:51,199 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 54310: starting
2015-05-02 19:01:51,227 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 54310: starting
2015-05-02 19:01:51,227 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 54310: starting
2015-05-02 19:01:52,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: node registration from 10.0.2.10:50010 storage DS-1947839898-127.0.1.1-50010-1430586112159
2015-05-02 19:01:52,291 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.2.10:50010
2015-05-02 19:01:52,309 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.blocksBeingWrittenReport: from 10.0.2.10:50010 0 blocks
2015-05-02 19:01:52,319 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* processReport: from 10.0.2.10:50010, blocks: 0, processing time: 0 msecs
2015-05-02 19:01:53,916 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: node registration from 10.0.2.9:50010 storage DS-1027390362-127.0.1.1-50010-1430586113904
2015-05-02 19:01:53,916 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.2.9:50010
2015-05-02 19:01:53,985 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.blocksBeingWrittenReport: from 10.0.2.9:50010 0 blocks
2015-05-02 19:01:54,070 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* processReport: from 10.0.2.9:50010, blocks: 0, processing time: 0 msecs

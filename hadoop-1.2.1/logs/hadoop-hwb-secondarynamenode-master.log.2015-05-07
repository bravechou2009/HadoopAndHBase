2015-05-07 10:46:45,701 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master/10.0.2.9
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.7.0_79
************************************************************/
2015-05-07 10:46:46,198 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: dfs.namenode.edits.toleration.length is set to 0.  Override it with -1, i.e. disable it.
2015-05-07 10:46:50,993 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-05-07 10:46:51,305 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-05-07 10:46:51,329 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50090
2015-05-07 10:46:51,347 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50090 webServer.getConnectors()[0].getLocalPort() returned 50090
2015-05-07 10:46:51,347 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50090
2015-05-07 10:46:51,347 INFO org.mortbay.log: jetty-6.1.26
2015-05-07 10:46:52,961 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50090
2015-05-07 10:46:52,961 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-05-07 10:46:52,961 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Secondary Web-server up at: 0.0.0.0:50090
2015-05-07 10:46:52,961 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-05-07 10:46:52,961 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :67108864 bytes (65536 KB)
2015-05-07 10:47:33,981 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master/10.0.2.9
************************************************************/
2015-05-07 10:47:53,476 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = master/10.0.2.9
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.7.0_79
************************************************************/
2015-05-07 10:47:53,936 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: dfs.namenode.edits.toleration.length is set to 0.  Override it with -1, i.e. disable it.
2015-05-07 10:47:58,179 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-05-07 10:47:58,675 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-05-07 10:47:58,678 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50090
2015-05-07 10:47:58,679 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50090 webServer.getConnectors()[0].getLocalPort() returned 50090
2015-05-07 10:47:58,679 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50090
2015-05-07 10:47:58,679 INFO org.mortbay.log: jetty-6.1.26
2015-05-07 10:48:00,699 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50090
2015-05-07 10:48:00,699 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-05-07 10:48:00,699 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Secondary Web-server up at: 0.0.0.0:50090
2015-05-07 10:48:00,699 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-05-07 10:48:00,699 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :67108864 bytes (65536 KB)
2015-05-07 10:53:01,341 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://0.0.0.0:50070/getimage?getimage=1
2015-05-07 10:53:01,514 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 8703 bytes.
2015-05-07 10:53:01,514 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://0.0.0.0:50070/getimage?getedit=1
2015-05-07 10:53:01,526 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 7101 bytes.
2015-05-07 10:53:01,536 INFO org.apache.hadoop.hdfs.util.GSet: Computing capacity for map BlocksMap
2015-05-07 10:53:01,536 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-05-07 10:53:01,536 INFO org.apache.hadoop.hdfs.util.GSet: 2.0% max memory = 1013645312
2015-05-07 10:53:01,536 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-05-07 10:53:01,536 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-05-07 10:53:01,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hwb
2015-05-07 10:53:01,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-05-07 10:53:01,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2015-05-07 10:53:01,803 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-05-07 10:53:01,803 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-05-07 10:53:01,822 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: dfs.namenode.edits.toleration.length = -1
2015-05-07 10:53:01,822 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-05-07 10:53:02,225 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 76
2015-05-07 10:53:02,256 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-05-07 10:53:02,257 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start loading edits file /tmp/hadoop-hwb/dfs/namesecondary/current/edits
2015-05-07 10:53:02,305 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: EOF of /tmp/hadoop-hwb/dfs/namesecondary/current/edits, reached end of edit log Number of transactions found: 61.  Bytes read: 7101
2015-05-07 10:53:02,308 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edits file /tmp/hadoop-hwb/dfs/namesecondary/current/edits of size 7101 edits # 61 loaded in 0 seconds.
2015-05-07 10:53:02,308 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-05-07 10:53:02,345 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: closing edit log: position=7101, editlog=/tmp/hadoop-hwb/dfs/namesecondary/current/edits
2015-05-07 10:53:02,346 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: close success: truncate to 7101, editlog=/tmp/hadoop-hwb/dfs/namesecondary/current/edits
2015-05-07 10:53:02,349 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /tmp/hadoop-hwb/dfs/namesecondary/current/fsimage of size 7777 bytes saved in 0 seconds.
2015-05-07 10:53:02,364 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: closing edit log: position=4, editlog=/tmp/hadoop-hwb/dfs/namesecondary/current/edits
2015-05-07 10:53:02,364 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: close success: truncate to 4, editlog=/tmp/hadoop-hwb/dfs/namesecondary/current/edits
2015-05-07 10:53:02,408 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Posted URL 0.0.0.0:50070putimage=1&port=50090&machine=0.0.0.0&token=-41:806621259:0:1430988780000:1430988470446&newChecksum=5f6683196cfcfcf6c785c4c74a9d0289
2015-05-07 10:53:02,408 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://0.0.0.0:50070/getimage?putimage=1&port=50090&machine=0.0.0.0&token=-41:806621259:0:1430988780000:1430988470446&newChecksum=5f6683196cfcfcf6c785c4c74a9d0289
2015-05-07 10:53:02,591 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 7777
2015-05-07 11:53:03,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/10.0.2.9:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2015-05-07 11:53:04,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/10.0.2.9:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2015-05-07 11:53:05,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/10.0.2.9:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2015-05-07 11:53:06,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/10.0.2.9:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2015-05-07 11:53:07,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/10.0.2.9:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2015-05-07 11:53:08,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/10.0.2.9:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2015-05-07 11:53:09,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/10.0.2.9:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2015-05-07 11:53:10,075 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at master/10.0.2.9
************************************************************/
